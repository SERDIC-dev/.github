# SERDIC AI Team Development Guide

ìµœì¢… ì—…ë°ì´íŠ¸: 2025.08.25.

ì‘ì„±ì: Chansoo Park

---

SERDIC AI Team Development Guide

1. ì˜ˆì‹œì´ë¯€ë¡œ ì•„ë˜ ë‚´ìš©ì„ ì°¸ì¡°í•˜ì—¬ í”„ë¡œì íŠ¸ë¥¼ êµ¬ì„±í•˜ë©´ ë©ë‹ˆë‹¤.
2. ëŒ€ìš©ëŸ‰ íŒŒì¼, ê°€ì¤‘ì¹˜, ì´ë¯¸ì§€ íŒŒì¼ë“¤ì„ ì‚¬ìš©í•´ì•¼ í•˜ëŠ” ê²½ìš°, NAS í´ë”ëª…ì„ ëª…ì‹œí•´ì„œ íŒŒì¼ì„ ì˜®ê¸¸ ìˆ˜ ìˆë„ë¡ í•´ì•¼ í•©ë‹ˆë‹¤.
3. ì§ì ‘ ì‘ì„±í•œ ì½”ë“œ ì™¸ì— ì˜¤í”ˆì†ŒìŠ¤ ì½”ë“œë“¤ë„ ì•„ë˜ ì–‘ì‹ì— ë§ê²Œ ìˆ˜ì • í•  í•„ìš”ëŠ” ì—†ìœ¼ë‚˜, í•„ìš” ì‹œ ìˆ˜ì • ê°€ëŠ¥í•©ë‹ˆë‹¤.


## ğŸ“‘ ëª©ì°¨
1. [í™˜ê²½ ì„¤ì •](#í™˜ê²½-ì„¤ì •)
2. [Coding Convention and Style](#coding-convention-and-style)
3. [ë ˆí¬ì§€í† ë¦¬ README ì‘ì„± ì–‘ì‹](#ë ˆí¬ì§€í† ë¦¬-readme-ì‘ì„±-ì–‘ì‹)
4. [ëª¨ë¸ êµ¬ë¶„ ë° êµ¬ì¡°](#ëª¨ë¸-êµ¬ë¶„-ë°-êµ¬ì¡°)

---

## âš™ï¸ í™˜ê²½ ì„¤ì •

### ì‹œìŠ¤í…œ í™˜ê²½

| í•­ëª© | ë²„ì „ | ë¹„ê³  |
|------|------|------|
| ìš´ì˜ì²´ì œ | Ubuntu 20.04/22.04 | Windows WSL2 ì§€ì› |
| Python | 3.8+ | 3.9 ê¶Œì¥ |
| CUDA | 11.8+ | RTX 30xx/40xx ì‹œë¦¬ì¦ˆ |
| cuDNN | 8.6+ | CUDA ë²„ì „ê³¼ í˜¸í™˜ |
| Docker | 20.10+ | ì»¨í…Œì´ë„ˆ í™˜ê²½ êµ¬ì¶•ìš© |

### Deep Learning Framework

| í”„ë ˆì„ì›Œí¬ | ë²„ì „ | ìš©ë„ |
|------------|------|------|
| PyTorch | 2.0+ | ë©”ì¸ í”„ë ˆì„ì›Œí¬ |
| TensorFlow | 2.10+ | Legacy ëª¨ë¸ ì§€ì› |
| OpenCV | 4.5+ | ì´ë¯¸ì§€ ì²˜ë¦¬ |
| ONNX | 1.14+ | ëª¨ë¸ ìµœì í™” |
| TensorRT | 8.5+ | ì¶”ë¡  ê°€ì†í™” |

### Conda ê°€ìƒí™˜ê²½ ì„¤ì •

```bash
# ìƒˆ í™˜ê²½ ìƒì„±
conda create -n ai_project python=3.9
conda activate ai_project

# PyTorch ì„¤ì¹˜ (CUDA 11.8)
conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia

# í•„ìˆ˜ íŒ¨í‚¤ì§€ ì„¤ì¹˜
pip install opencv-python numpy pandas matplotlib seaborn
pip install ultralytics transformers accelerate
pip install tensorboard wandb

# í™˜ê²½ ë‚´ë³´ë‚´ê¸°
conda env export > environment.yml
```

### Docker í™˜ê²½ ì„¤ì •

```dockerfile
FROM pytorch/pytorch:2.0.1-cuda11.7-cudnn8-devel

WORKDIR /workspace

# ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1 \
    libgl1-mesa-glx libglib2.0-0

# Python íŒ¨í‚¤ì§€ ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
ENV PYTHONPATH=/workspace
ENV CUDA_VISIBLE_DEVICES=0
```

### í™˜ê²½ ë³€ìˆ˜ ì„¤ì •

```bash
# ~/.bashrc ë˜ëŠ” .env íŒŒì¼ì— ì¶”ê°€
export CUDA_VISIBLE_DEVICES=0
export PYTHONPATH="${PYTHONPATH}:/path/to/project"
export WANDB_API_KEY="your_wandb_key"
export HF_HOME="/path/to/huggingface_cache"
```

---

## ğŸ“‹ Coding Convention and Style

### í´ë˜ìŠ¤ êµ¬ì¡°

```python
class Detector:
    """
    Description:
        AI Based Object Detection Module
        
    Attributes:
        model_path (str): ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
        device (str): ì¶”ë¡  ë””ë°”ì´ìŠ¤ (cpu/cuda)
        confidence (float): ì‹ ë¢°ë„ ì„ê³„ê°’
        
    Methods:
        load_model: ëª¨ë¸ ë¡œë“œ
        preprocess: ì „ì²˜ë¦¬
        inference: ì¶”ë¡ 
        postprocess: í›„ì²˜ë¦¬
        run: ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        release: ë¦¬ì†ŒìŠ¤ í•´ì œ
    """
    
    def __init__(self, model_path: str, device: str = "cuda", confidence: float = 0.5):
        """
        Detection í´ë˜ìŠ¤ ì´ˆê¸°í™”
        
        Args:
            model_path (str): ëª¨ë¸ íŒŒì¼ ê²½ë¡œ
            device (str): ì¶”ë¡  ë””ë°”ì´ìŠ¤
            confidence (float): ì‹ ë¢°ë„ ì„ê³„ê°’
        """
        self.model_path = model_path
        self.device = device
        self.confidence = confidence
        self.model = None
        
    def load_model(self) -> None:
        """ëª¨ë¸ ë¡œë“œ ë° ì´ˆê¸°í™”"""
        try:
            # ëª¨ë¸ ë¡œë“œ ë¡œì§
            self.model = torch.load(self.model_path)
            self.model.to(self.device)
            self.model.eval()
        except Exception as e:
            raise RuntimeError(f"Model loading failed: {e}")
    
    def preprocess(self, image: np.ndarray) -> torch.Tensor:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        
        Args:
            image (np.ndarray): ì…ë ¥ ì´ë¯¸ì§€ (H, W, C)
            
        Returns:
            torch.Tensor: ì „ì²˜ë¦¬ëœ í…ì„œ (1, C, H, W)
        """
        # ì „ì²˜ë¦¬ ë¡œì§
        pass
    
    def inference(self, tensor: torch.Tensor) -> torch.Tensor:
        """
        ëª¨ë¸ ì¶”ë¡ 
        
        Args:
            tensor (torch.Tensor): ì „ì²˜ë¦¬ëœ ì…ë ¥ í…ì„œ
            
        Returns:
            torch.Tensor: ì¶”ë¡  ê²°ê³¼
        """
        with torch.no_grad():
            outputs = self.model(tensor)
        return outputs
    
    def postprocess(self, outputs: torch.Tensor) -> List[Dict]:
        """
        ì¶”ë¡  ê²°ê³¼ í›„ì²˜ë¦¬
        
        Args:
            outputs (torch.Tensor): ëª¨ë¸ ì¶œë ¥
            
        Returns:
            List[Dict]: ê²€ì¶œ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # í›„ì²˜ë¦¬ ë¡œì§
        pass
    
    def run(self, image: np.ndarray) -> List[Dict]:
        """
        ì „ì²´ ì¶”ë¡  íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Args:
            image (np.ndarray): ì…ë ¥ ì´ë¯¸ì§€ (H, W, C)
            
        Returns:
            List[Dict]: ê²€ì¶œ ê²°ê³¼
                - bbox: ë°”ìš´ë”© ë°•ìŠ¤ ì¢Œí‘œ [x1, y1, x2, y2]
                - confidence: ì‹ ë¢°ë„ ì ìˆ˜
                - class_id: í´ë˜ìŠ¤ ID
                - class_name: í´ë˜ìŠ¤ ì´ë¦„
        """
        tensor = self.preprocess(image)
        outputs = self.inference(tensor)
        results = self.postprocess(outputs)
        return results
    
    def release(self) -> None:
        """ë¦¬ì†ŒìŠ¤ í•´ì œ"""
        if self.model is not None:
            del self.model
            torch.cuda.empty_cache()

# ì‚¬ìš© ì˜ˆì‹œ
detector = Detector("models/yolo_v8n.pt", device="cuda", confidence=0.5)
detector.load_model()

# ì¶”ë¡  ì‹¤í–‰
image = cv2.imread("sample.jpg")
results = detector.run(image)

# ê²°ê³¼ ì¶œë ¥
for result in results:
    print(f"Class: {result['class_name']}, Confidence: {result['confidence']:.2f}")
```

### í•¨ìˆ˜ ë° ë³€ìˆ˜ ëª…ëª… ê·œì¹™

```python
# ë³€ìˆ˜ëª…: snake_case
model_path = "models/detector.pt"
batch_size = 32
learning_rate = 0.001

# í•¨ìˆ˜ëª…: snake_case + ë™ì‚¬í˜•
def load_model():
    pass

def preprocess_image():
    pass

def calculate_accuracy():
    pass

# í´ë˜ìŠ¤ëª…: PascalCase
class ObjectDetector:
    pass

class DataLoader:
    pass

# ìƒìˆ˜: UPPER_CASE
MAX_BATCH_SIZE = 64
DEFAULT_CONFIDENCE = 0.5
MODEL_INPUT_SIZE = (640, 640)
```

### íƒ€ì… íŒíŒ… ê·œì¹™

```python
from typing import List, Dict, Tuple, Optional, Union
import numpy as np
import torch

def train_model(
    model: torch.nn.Module,
    dataloader: torch.utils.data.DataLoader,
    optimizer: torch.optim.Optimizer,
    epochs: int,
    device: str = "cuda"
) -> Tuple[float, float]:
    """
    ëª¨ë¸ í›ˆë ¨ í•¨ìˆ˜
    
    Args:
        model: í›ˆë ¨í•  ëª¨ë¸
        dataloader: ë°ì´í„°ë¡œë”
        optimizer: ì˜µí‹°ë§ˆì´ì €
        epochs: í›ˆë ¨ ì—í¬í¬ ìˆ˜
        device: ë””ë°”ì´ìŠ¤
        
    Returns:
        Tuple[float, float]: (train_loss, train_accuracy)
    """
    pass
```

### ì—ëŸ¬ ì²˜ë¦¬ ê·œì¹™

```python
import logging

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class ModelError(Exception):
    """ëª¨ë¸ ê´€ë ¨ ì»¤ìŠ¤í…€ ì˜ˆì™¸"""
    pass

def load_model(model_path: str) -> torch.nn.Module:
    """ì•ˆì „í•œ ëª¨ë¸ ë¡œë“œ"""
    try:
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"Model file not found: {model_path}")
            
        model = torch.load(model_path)
        logger.info(f"Model loaded successfully: {model_path}")
        return model
        
    except torch.serialization.UnicodeDecodeError:
        raise ModelError(f"Invalid model format: {model_path}")
    except Exception as e:
        logger.error(f"Unexpected error loading model: {e}")
        raise
```

---

## ğŸ“„ ë ˆí¬ì§€í† ë¦¬ README ì‘ì„± ì–‘ì‹

### ê¸°ë³¸ êµ¬ì¡°

```markdown
# í”„ë¡œì íŠ¸ëª…

## ğŸ“‹ ê°œìš”
- í”„ë¡œì íŠ¸ ëª©ì  ë° ì„¤ëª…
- ì£¼ìš” ê¸°ëŠ¥

## ğŸ”§ í™˜ê²½ ì„¤ì •
- Python ë²„ì „
- CUDA ë²„ì „  
- í•„ìš” íŒ¨í‚¤ì§€

## ğŸ“Š ëª¨ë¸ ì •ë³´
- ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸
- ì„±ëŠ¥ ì§€í‘œ
- ë ˆí¼ëŸ°ìŠ¤

## ğŸš€ ì‚¬ìš©ë²•
- ì„¤ì¹˜ ë°©ë²•
- ì‹¤í–‰ ì˜ˆì‹œ

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°
```

### ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸ ë ˆí¼ëŸ°ìŠ¤ ì‘ì„±ë²•

```markdown
## ğŸ“Š ë² ì´ìŠ¤ë¼ì¸ ëª¨ë¸

### YOLOv8 Object Detection
- **GitHub**: [ultralytics/ultralytics](https://github.com/ultralytics/ultralytics)
- **Paper**: [YOLOv8: A New Vision Transformer for Object Detection](https://arxiv.org/abs/2301.00331)
- **Model**: YOLOv8n/s/m/l/x variants
- **Performance**: mAP@0.5:0.95 = 37.3% (COCO dataset)

### SAM2 (Segment Anything Model 2)
- **GitHub**: [facebookresearch/segment-anything-2](https://github.com/facebookresearch/segment-anything-2)
- **Paper**: [SAM 2: Segment Anything in Images and Videos](https://arxiv.org/abs/2408.00714)
- **Model**: SAM2-B/L/H variants
- **Performance**: IoU@0.5 = 85.2% (SA-V dataset)

### Custom Fine-tuning
- **Base Model**: YOLOv8m
- **Dataset**: Custom industrial dataset (10K images)
- **Performance**: mAP@0.5 = 92.1% (validation set)
- **Training Details**: 100 epochs, AdamW optimizer, lr=0.001
```

---

## ğŸ—ï¸ ëª¨ë¸ êµ¬ë¶„ ë° êµ¬ì¡°

### ë‹¨ìˆœ ì¶”ë¡  ëª¨ë¸ (Inference Only)

```
project/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ detector.pt          # ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸
â”‚   â””â”€â”€ config.yaml         # ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ inference.py        # ì¶”ë¡  ëª¨ë“ˆ
â”‚   â”œâ”€â”€ preprocess.py       # ì „ì²˜ë¦¬
â”‚   â””â”€â”€ postprocess.py      # í›„ì²˜ë¦¬
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ visualize.py        # ì‹œê°í™”
â”‚   â””â”€â”€ metrics.py          # í‰ê°€ ì§€í‘œ
â”œâ”€â”€ examples/
â”‚   â””â”€â”€ demo.py            # ì‚¬ìš© ì˜ˆì‹œ
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ run_inference.py       # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
```

#### ì¶”ë¡  ì „ìš© README í…œí”Œë¦¿

```markdown
# AI Object Detection - Inference Only

## ğŸ¯ ëª¨ë¸ ì •ë³´
- **Task**: Object Detection
- **Model**: YOLOv8m
- **Input Size**: 640x640
- **Classes**: 80 (COCO classes)

## âš¡ ë¹ ë¥¸ ì‹œì‘
```bash
# ì˜ì¡´ì„± ì„¤ì¹˜
pip install -r requirements.txt

# ë‹¨ì¼ ì´ë¯¸ì§€ ì¶”ë¡ 
python run_inference.py --image path/to/image.jpg

# ë°°ì¹˜ ì¶”ë¡ 
python run_inference.py --folder path/to/images/
```

## ğŸ“ˆ ì„±ëŠ¥
- **mAP@0.5**: 65.2%
- **Inference Speed**: 45 FPS (RTX 3080)
- **Model Size**: 52MB


### Fine-tuning ì§€ì› ëª¨ë¸ (Train/Val/Eval)

```
project/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train/              # í›ˆë ¨ ë°ì´í„°
â”‚   â”œâ”€â”€ val/                # ê²€ì¦ ë°ì´í„°
â”‚   â”œâ”€â”€ test/               # í…ŒìŠ¤íŠ¸ ë°ì´í„°
â”‚   â””â”€â”€ annotations/        # ì–´ë…¸í…Œì´ì…˜ íŒŒì¼
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ pretrained/         # ì‚¬ì „ í›ˆë ¨ ëª¨ë¸
â”‚   â”œâ”€â”€ checkpoints/        # ì²´í¬í¬ì¸íŠ¸
â”‚   â””â”€â”€ configs/            # ëª¨ë¸ ì„¤ì • íŒŒì¼
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ train.py            # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ validate.py         # ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ inference.py        # ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ dataset.py          # ë°ì´í„°ì…‹ í´ë˜ìŠ¤
â”‚   â””â”€â”€ model.py           # ëª¨ë¸ ì •ì˜
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ logger.py          # ë¡œê¹…
â”‚   â”œâ”€â”€ metrics.py         # í‰ê°€ ì§€í‘œ
â”‚   â””â”€â”€ augmentation.py    # ë°ì´í„° ì¦ê°•
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ train_config.yaml   # í›ˆë ¨ ì„¤ì •
â”‚   â””â”€â”€ model_config.yaml   # ëª¨ë¸ ì„¤ì •
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ train.sh           # í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ evaluate.sh        # í‰ê°€ ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ data_analysis.ipynb # ë°ì´í„° ë¶„ì„
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ main.py                # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
```

#### Fine-tuning ì§€ì› README í…œí”Œë¦¿

```markdown
# AI Object Detection - Training & Inference

## ğŸ¯ ëª¨ë¸ ì •ë³´
- **Task**: Custom Object Detection
- **Base Model**: YOLOv8m
- **Fine-tuning**: Supported
- **Classes**: Custom 5 classes

## ğŸ”§ ë°ì´í„° ì¤€ë¹„
```bash
# ë°ì´í„° êµ¬ì¡°
data/
â”œâ”€â”€ train/
â”œâ”€â”€ val/
â””â”€â”€ annotations/
    â”œâ”€â”€ train.json
    â””â”€â”€ val.json
```

## ğŸš€ í›ˆë ¨
```bash
# ê¸°ë³¸ í›ˆë ¨
python src/train.py --config configs/train_config.yaml

# ë©€í‹° GPU í›ˆë ¨
python -m torch.distributed.launch --nproc_per_node=2 src/train.py
```

## ğŸ“Š í‰ê°€
```bash
# ëª¨ë¸ í‰ê°€
python src/validate.py --model models/checkpoints/best.pt --data data/val/

# í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ ì¶”ë¡ 
python src/inference.py --model models/checkpoints/best.pt --source data/test/
```

## ğŸ“ˆ ì„±ëŠ¥
- **Training mAP@0.5**: 89.3%
- **Validation mAP@0.5**: 87.1%
- **Training Time**: 2 hours (RTX 3080)
```
